export MODEL_DIR=sinhala-t5-small
./run_t5_mlm_flax.py \
	--output_dir="${MODEL_DIR}" \
	--model_type="t5" \
	--config_name="${MODEL_DIR}" \
	--tokenizer_name="${MODEL_DIR}" \
	--dataset_name="mc4" \
	--dataset_config_name="si" \
	--max_seq_length="512" \
	--per_device_train_batch_size="16" \
	--per_device_eval_batch_size="16" \
	--learning_rate="1e-3" \
	--weight_decay="0.001" \
	--warmup_steps="5000" \
	--overwrite_output_dir \
	--num_train_epochs="10" \
	--logging_steps="500" \
	--save_steps="2500" \
	--eval_steps="2500" \
	--push_to_hub
